{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a52a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_lightning.utilities.memory import garbage_collection_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e22403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov3 import YOLOv3\n",
    "from utils import get_loaders, load_checkpoint, check_class_accuracy, intersection_over_union\n",
    "import config\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a40bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import YoloLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5b2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv3Lightning(pl.LightningModule):\n",
    "    def __init__(self,lr_value=0):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = YOLOv3(num_classes=self.config.NUM_CLASSES)\n",
    "        self.loss_fn = YoloLoss()\n",
    "        if lr_value == 0:\n",
    "          self.learning_rate = self.config.LEARNING_RATE\n",
    "        else:\n",
    "          self.learning_rate = lr_value\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.config.LEARNING_RATE, weight_decay=self.config.WEIGHT_DECAY)\n",
    "        EPOCHS = self.config.NUM_EPOCHS * 2 // 5\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=1E-3, steps_per_epoch=len(self.train_dataloader()), epochs=EPOCHS, pct_start=5/EPOCHS, div_factor=100, three_phase=False, final_div_factor=100, anneal_strategy='linear')\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n",
    "\n",
    "    \n",
    "    def get_all_loaders(self):\n",
    "        train_loader, test_loader, val_loader = get_loaders(\n",
    "            train_csv_path=self.config.DATASET + \"/train.csv\",\n",
    "            test_csv_path=self.config.DATASET + \"/test.csv\",\n",
    "        )\n",
    "        return train_loader,test_loader, val_loader \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader, _, _ = self.get_all_loaders()\n",
    "        return train_loader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y0, y1, y2 = (y[0].to(self.device),y[1].to(self.device),y[2].to(self.device))\n",
    "        out = self(x)\n",
    "\n",
    "        loss = (\n",
    "            self.loss_fn(out[0], y0, self.scaled_anchors[0])\n",
    "            + self.loss_fn(out[1], y1, self.scaled_anchors[1])\n",
    "            + self.loss_fn(out[2], y2, self.scaled_anchors[2])\n",
    ")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_dataloader(self):\n",
    "        _,  _, val_loader = self.get_all_loaders()\n",
    "        return val_loader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y0, y1, y2 = (\n",
    "            y[0].to(self.device),\n",
    "            y[1].to(self.device),\n",
    "            y[2].to(self.device),\n",
    "        )\n",
    "        out = self(x)\n",
    "        loss = (\n",
    "            self.loss_fn(out[0], y0, self.scaled_anchors[0])\n",
    "            + self.loss_fn(out[1], y1, self.scaled_anchors[1])\n",
    "            + self.loss_fn(out[2], y2, self.scaled_anchors[2])\n",
    "        )\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "  \n",
    "\n",
    "    def test_dataloader(self):\n",
    "        _, test_loader, _ = self.get_all_loaders()\n",
    "        return test_loader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y0, y1, y2 = (\n",
    "            y[0].to(self.device),\n",
    "            y[1].to(self.device),\n",
    "            y[2].to(self.device),\n",
    "        )\n",
    "        out = self(x)\n",
    "        loss = (\n",
    "            self.loss_fn(out[0], y0, self.scaled_anchors[0])\n",
    "            + self.loss_fn(out[1], y1, self.scaled_anchors[1])\n",
    "            + self.loss_fn(out[2], y2, self.scaled_anchors[2])\n",
    "        )\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        if self.config.LOAD_MODEL:\n",
    "            load_checkpoint(self.config.CHECKPOINT_FILE, self.model, self.optimizers(), self.config.LEARNING_RATE)\n",
    "        self.scaled_anchors = (\n",
    "            torch.tensor(self.config.ANCHORS)\n",
    "            * torch.tensor(self.config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
    "        ).to(self.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488713c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
